{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1982, 41)\n",
      "[[1.         1.         1.         ... 0.         0.         1.        ]\n",
      " [0.         0.         0.83       ... 0.         0.         1.        ]\n",
      " [1.         0.91       0.98       ... 0.         0.         1.        ]\n",
      " ...\n",
      " [1.         1.         0.95       ... 0.         0.         1.        ]\n",
      " [1.         1.         0.95       ... 0.         0.         1.        ]\n",
      " [0.68260619 0.8        0.5        ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1982, 41)\n",
      "[[1.         1.         1.         ... 0.         0.         1.        ]\n",
      " [0.         0.         0.83       ... 0.         0.         1.        ]\n",
      " [1.         0.91       0.98       ... 0.         0.         1.        ]\n",
      " ...\n",
      " [1.         1.         0.95       ... 0.         0.         1.        ]\n",
      " [1.         1.         0.95       ... 0.         0.         1.        ]\n",
      " [0.68260619 0.8        0.5        ... 0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statlearning import plot_dist, plot_dists, plot_regressions\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_copy = copy.deepcopy(train)\n",
    "test_copy = copy.deepcopy(test)\n",
    "train.head()\n",
    "\n",
    "train_dimensions = np.shape(train)\n",
    "test_dimensions = np.shape(test)\n",
    "\n",
    "\n",
    "# print(test_dimensions)\n",
    "# print(train_dimensions)\n",
    "# print(train_copy.isna().sum())\n",
    "\n",
    "# --------------------数据处理-------------------------#\n",
    "# 填充数字的具体方法，到时候你们自己看着改\n",
    "def fill_cvs(copy_name, copy_type):\n",
    "    review_columns = ['review_scores_rating', 'review_scores_accuracy',\n",
    "                      'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                      'review_scores_communication', 'review_scores_location',\n",
    "                      'reviews_per_month', 'review_scores_value',\n",
    "                      ]\n",
    "    host_columns = ['host_is_superhost', 'host_identity_verified']\n",
    "    room_columns = ['bedrooms', 'beds']\n",
    "    copy_name['host_response_time'].fillna('never response', inplace=True)\n",
    "    copy_name['host_response_rate'].fillna(0, inplace=True)\n",
    "    copy_name['host_acceptance_rate'].fillna(0, inplace=True)\n",
    "    copy_name['security_deposit'].fillna(copy_name['security_deposit'].mean(), inplace=True)\n",
    "    clean_fee_median = copy_name['cleaning_fee'].median()\n",
    "    copy_name['cleaning_fee'][np.isnan(copy_name['cleaning_fee'])] = clean_fee_median\n",
    "    copy_name['latitude'] = np.absolute(copy_name['latitude'])\n",
    "    copy_name[review_columns] = copy_name[review_columns].interpolate(limit_direction='backward')\n",
    "    copy_name[host_columns] = copy_name[host_columns].fillna('f')\n",
    "    for item in room_columns:\n",
    "        copy_name[item].fillna(copy_name[item].mean(), inplace=True)\n",
    "    if copy_type == 'train':\n",
    "        copy_name = copy_name.dropna()\n",
    "\n",
    "    return copy_name\n",
    "\n",
    "\n",
    "train_copy = fill_cvs(train_copy, 'train')\n",
    "test_copy = fill_cvs(test_copy, 'test')\n",
    "# print(test_copy['latitude'])\n",
    "# print(train_copy.isna().sum())\n",
    "# print('----------------')\n",
    "# print(test_copy.isna().sum())\n",
    "# print(np.shape(train_copy))\n",
    "# print(np.shape(test_copy))\n",
    "\n",
    "train_copy_for_fe = copy.deepcopy(train_copy)\n",
    "test_copy_for_fe = copy.deepcopy(test_copy)\n",
    "\n",
    "\n",
    "# 文本，boolean的数据类型量化\n",
    "def fe_cvs(fe_copy):\n",
    "    response_time_map = {'within an hour': 4,\n",
    "                         'within a few hours': 3,\n",
    "                         'within a day': 2,\n",
    "                         'a few days or more': 1,\n",
    "                         'never response': 0}\n",
    "\n",
    "    cancellation_policy_map = {\n",
    "        'flexible': 4,\n",
    "        'moderate': 3,\n",
    "        'strict_14_with_grace_period': 2,\n",
    "        'super_strict_30': 1,\n",
    "        'super_strict_60': 0\n",
    "    }\n",
    "\n",
    "    boolean2int_map = {'t': 1,\n",
    "                       'f': 0}\n",
    "    boolean2int_list = ['host_identity_verified', 'instant_bookable', 'require_guest_profile_picture',\n",
    "                        'require_guest_phone_verification', 'host_is_superhost']\n",
    "    fe_copy['host_response_time'] = fe_copy['host_response_time'].map(response_time_map)\n",
    "    fe_copy['cancellation_policy'] = fe_copy['cancellation_policy'].map(cancellation_policy_map)\n",
    "    for item in boolean2int_list:\n",
    "        fe_copy[item] = fe_copy[item].map(boolean2int_map)\n",
    "\n",
    "    return fe_copy\n",
    "\n",
    "\n",
    "train_copy_for_fe = fe_cvs(train_copy_for_fe)\n",
    "test_copy_for_fe = fe_cvs(test_copy_for_fe)\n",
    "\n",
    "\n",
    "# print(train_copy_for_fe.isna().sum())\n",
    "# print(test_copy_for_fe.isna().sum())\n",
    "\n",
    "# print(pd.crosstab(index=train_copy_for_fe['property_type'], columns='count'))\n",
    "# print(pd.crosstab(index=train_copy_for_fe['room_type'], columns='count'))\n",
    "\n",
    "# 对数据量比较少的种类合并\n",
    "def merge_redundant(fe_copy):\n",
    "    fe_copy['property_type'] = np.where(fe_copy['property_type'].str.contains('House'), 'House',\n",
    "                                        (np.where(fe_copy['property_type'].str.contains('Apartment'), 'Apartment',\n",
    "                                                  np.where(fe_copy['property_type'].str.contains('Townhouse'),\n",
    "                                                           'Townhouse', 'Other type')))\n",
    "                                        )\n",
    "\n",
    "    fe_copy['room_type'] = np.where(fe_copy['room_type'].str.contains('Private room'), 'Private room',\n",
    "                                    (np.where(fe_copy['room_type'].str.contains('Entire home/apt'),\n",
    "                                              'Entire home/apt', 'Other type')))\n",
    "\n",
    "    return fe_copy\n",
    "\n",
    "\n",
    "train_copy_for_fe = merge_redundant(train_copy_for_fe)\n",
    "test_copy_for_fe = merge_redundant(test_copy_for_fe)\n",
    "\n",
    "\n",
    "# print(pd.crosstab(index=train_copy_for_fe['property_type'], columns='count'))\n",
    "# print(pd.crosstab(index=train_copy_for_fe['room_type'], columns='count'))\n",
    "def dummy_create(dm_copy):\n",
    "    dm_copy = copy.deepcopy(pd.get_dummies(dm_copy, drop_first=True))\n",
    "    # print(dm_copy.head)\n",
    "    return dm_copy\n",
    "\n",
    "\n",
    "test_copy_for_dm = dummy_create(test_copy_for_fe)\n",
    "train_copy_for_dm = dummy_create(train_copy_for_fe)\n",
    "\n",
    "# -----------分析数据------------#\n",
    "\"\"\"\n",
    "\n",
    "根据数据类型种类分为两个组：\n",
    "如果只有0 1在dummy里，如果很复杂就在other里\n",
    "\n",
    "\"\"\"\n",
    "# values 0 or 1\n",
    "dummy_list = []\n",
    "# other values type\n",
    "other_list = []\n",
    "\n",
    "for item in train_copy_for_dm.columns:\n",
    "    # print(item, '---', train_copy_for_dm[item].value_counts().shape[0])\n",
    "    if item == 'Id':\n",
    "        continue\n",
    "    if train_copy_for_dm[item].value_counts().shape[0] > 2:\n",
    "        other_list.append(item)\n",
    "    else:\n",
    "        dummy_list.append(item)\n",
    "# print(dummy_list)\n",
    "# print(other_list)\n",
    "\n",
    "train_des = train_copy_for_fe.describe()\n",
    "train_des.loc['skew', :] = train_copy_for_dm.skew()\n",
    "train_des.loc['kurt', :] = train_copy_for_dm.kurt()\n",
    "train_des[other_list].round(3)\n",
    "\n",
    "\n",
    "# ------------画图---------------#\n",
    "def draw(train_model):\n",
    "    log_y_train = np.log(train_model['price'])\n",
    "    plot_dist(log_y_train)\n",
    "    plt.title('tmp')\n",
    "    plt.show()\n",
    "\n",
    "    plot_dists(train_model[other_list])\n",
    "    plt.show()\n",
    "    reg_other = copy.deepcopy(other_list)\n",
    "    reg_other.remove('price')\n",
    "    plot_regressions(train_model[reg_other], train_model['price'])\n",
    "    plt.show()\n",
    "\n",
    "    sns.boxplot(x=train_model.loc[:, 'bed_type_Real Bed'], y=train_model.loc[:, 'price'], palette='Blues')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "    # 对 'host_identity_verified', 'host_response_time','cancellation_policy' 做同样的图\n",
    "\n",
    "    rows = train_model['accommodates'] <= 12\n",
    "    sns.boxplot(x=train_copy_for_dm.loc[rows, 'accommodates'], y=train_model.loc[rows, 'price'], palette='Blues')\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "    corr_map = train_model.corr()['price'].sort_values()\n",
    "    # print(corr_map)\n",
    "    COR_THRESHOLD = 0.08\n",
    "    train_cor = train_model[corr_map.loc[(corr_map > COR_THRESHOLD) | (corr_map < -COR_THRESHOLD)].index]\n",
    "    plt.subplots(figsize=(20, 15))\n",
    "    sns.heatmap(train_cor.corr(), square=True, annot=True, cmap=\"Accent\")\n",
    "    plt.title(\"heap map\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# draw(train_copy_for_dm)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------#\n",
    "\n",
    "# 删除异常值，自己看前面的图，删一些离谱的数据\n",
    "train_copy_for_dm = train_copy_for_dm[-((train_copy_for_dm['extra_people'] > 100) |\n",
    "                                        (train_copy_for_dm['security_deposit'] > 2000))]\n",
    "print(train_copy_for_dm.shape)\n",
    "\n",
    "# -------------------------#\n",
    "\n",
    "\n",
    "log_train = copy.deepcopy(train_copy_for_dm)\n",
    "log_test = copy.deepcopy(test_copy_for_dm)\n",
    "\n",
    "des = log_train.describe()\n",
    "des.loc['skew', :] = log_train.skew()\n",
    "des.loc['kurt', :] = log_train.kurt()\n",
    "des = des[other_list].T\n",
    "# print(des)\n",
    "positive_skewed = des.loc[des['skew'] > 0].index\n",
    "for skewed in positive_skewed[1:]:\n",
    "    log_train[skewed] = np.log(log_train[skewed] + 1)\n",
    "    log_test[skewed] = np.log(log_train[skewed] + 1)\n",
    "log_train['price'] = np.log(log_train['price'])\n",
    "\n",
    "x_train_log = log_train.drop(['price', 'Id'], axis=1)\n",
    "y_train_log = log_train['price']\n",
    "x_test_log = log_train.drop(['Id'], axis=1)\n",
    "\n",
    "# -------------------------scaling-------------------------- #\n",
    "\"\"\"\n",
    "选择method1 or method2\n",
    "\"\"\"\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "# method1\n",
    "x_train_log_mm_sacled = min_max_scaler.fit_transform(x_train_log)\n",
    "x_test_log_mm_sacled = min_max_scaler.transform(x_train_log)\n",
    "# method2\n",
    "x_train_log_standard_sacled = standard_scaler.fit_transform(x_train_log)\n",
    "x_test_log_standard_sacled = standard_scaler.transform(x_train_log)\n",
    "\n",
    "print(x_test_log_mm_sacled)\n",
    "\n",
    "# x_something -->完成数据处理后的矩阵，用这个信息和y_train作图，做出来新图重新分析，写在rep里\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
